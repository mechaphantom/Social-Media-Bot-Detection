# A Comparative Study of Learning Paradigms for Social Media Bot Detection

This project presents a comparative study of multiple learning paradigms for social media bot detection using a Twitter Human-Bots dataset rich in profile, behavioral, and limited textual features. The goal is to evaluate how classical machine learning, deep learning, and transformer-based models differ in their ability to distinguish human and bot accounts, and to show that traditional machine learning remains competitive against modern deep learning approaches. The methodology covers supervised (RNN, Random Forest, Linear and RBF SVM), self‑supervised (fine‑tuned BERT), and unsupervised (K-Means, Isolation Forest) models, with systematic data preprocessing, feature engineering on metadata and text, and evaluation via accuracy, precision, recall, and F1-score. Experimental results indicate that supervised models perform best overall, with RBF SVM and Random Forest achieving the strongest accuracy and F1 scores, while BERT provides competitive performance by leveraging user biographies. In contrast, unsupervised methods struggle as standalone classifiers when relying only on numerical metadata but are useful as auxiliary anomaly detectors for emerging bot behaviors. Overall, the study concludes that well‑designed classical machine learning models, especially RBF SVM, offer an effective, interpretable, and resource‑efficient baseline for social media bot detection, and that hybrid pipelines combining supervised, self‑supervised, and unsupervised components are a promising direction for future work

[Manuscript](BotAnalysisPaper.pdf)
